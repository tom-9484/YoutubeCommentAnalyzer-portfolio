# YouTubeCommentAnalyzer-java portfolio
#### 概要
職業訓練校の卒業課題ポートフォリオその2  
youtubeのライブ配信コメントをリアルタイムで収集  
マイクロソフトのAzure AI LanguageのAPIを使用し収集したコメントを点数付けし  
0.3点より大きければポジティブ-0.3点より小さければネガティブとする感情分析を行う  
その計測結果をcsvファイルで出力するプログラム  
virtual youtuberの長時間配信のコメントの様子を自動で収集し  
配信の切り抜き動画編集の効率を大幅に上げるために制作  
元々自分のために作ったものだが、vtuberだけでなく何かしら超長時間配信の切り抜き動画編集のために使用可能  
#### 開発期間
24日・約250時間
#### 使用技術
言語:Java（JDK21）＋ Maven（依存管理）  
API利用時の認証:OAuth2.0認証（youtube api利用時）  
使用API:YouTube Data API v3, Microsoft Azure AI Language–Sentiment Analysis API  
サーバー:AWS EC2 (OS:Ubuntu)  
Git GitHub
#### 大変だったこと
1.メインのコメント収集プログラムを作る以前のOAtuth2.0認証が何をすればいいのか分からず樹海に放り出される  

2.コメント収集のプログラムはPythonでサンプルコードがたくさん転がっているから  
　何とかなるだろうと思ってみたら無限にメソッドが出てきて何がなんだかわからない  
　それらをほどきながらjavaに書き換えなければならなかった  
  
3.無限にメソッドが出てくる理由がyoutube apiに色々仕様がたくさんあったからであり  
　youtube api使うためにわかりにくい公式ドキュメントを読まなければならなかった  
 
4.コードを書く上でjavaやGoogleが用意してるパッケージをimportとしなければならず  
　何を使えばいいのか五里霧中の迷子  
  
5.mavenってなに？依存関係ってなに？？からpom.xmlファイルを作成しなければならなかった  

6.filterやcollect、map、データの流れであるストリームに変換する.stream()など  
　Javaに備えられたStream APIという機能を理解しなければならなかった  
  
7.Youtube APIを使う時にGoogle が公式で提供しているクライアントライブラリの  
　Google API Client Library for Javaを使ったが  
　この中に用意されているYoutubeクラスの構造を把握しなければならず  
　「YouTubeクラス」の内部クラスである「LiveChatMessagesクラスのlist()メソッド」を呼び出すと、  
　LiveChatMessageListResponseオブジェクトが返され、それはitems[] 配列と示され  
　その0番目に格納されたLiveChatMessageオブジェクトが格納されており  
　そのLiveChatMessageの中のsnippetオブジェクトの中に  
　プロパティ(コメント本文や投稿時刻などのメッセージ情報の文字列)が存在する  
　といったことを理解しなければいけなかった  
   
8.youtubeコメント収集を乗り越えた先に今度はazure apiの使用ということで構造把握地獄で一度心が折れた  

9.Azure APIではライブラリを使わずにHTTPベースのREST APIを直接叩いたため  
　HttpRequestクラスで .uri .header .POST .build()といったメソッドを連打し  
　httpClientで.sendすることの理解が必要だった  

10.感情分析した結果を表示、集計、csvファイルに出力する時の処理をどうすべきか検索した結果  
　 データのストリーム変換とラムダ式、ジェネリスク記号と今まで出てきた要素が大量に出てきて頭が爆発した

11.Azure APIリクエスト用のJSONデータを作成する必要があったため  
　 SONライブラリを知る必要があった  
　 またJSONデータ作成のための書式設定と特殊記号のエスケープ処理が  
　 思った以上にわかりにくくてしんどかった  

12.コードを書き終えて完成だ、と喜びながらAWSのEC2サービスを使いクラウドサーバーを立てたはいいが  
　 今度はlinux系OSのCUIのコマンドをとにかく調べながら操作  
　 またpemファイルの権限変更やらssh接続がうまくいかずに気が狂いだす

13.プログラムがサーバー上で動いた時は涙出た  

#### 改善点
最初は認証処理、コメント収集処理、集計処理とそれぞれの処理でファイルを分けていたが  
実力不足によりファイルを分割していると自分が何をしているのかだんだんわけわからなくなってしまい  
結局、コメント収集から集計の処理に関しては1ファイルに統合してしまった  
変に使わないファイルが2つあるのはその時の名残(自分が躓いたところも多くあるので消さずに残している)  
自分のキーでサーバー接続してそこでjavaを動かしてるので自分にしか使えない  
非エンジニアの人が使えるようにローカルで配布して実行すると環境構築まで全部するようにするか  
必要な情報をブラウザ上で入力すれば起動するようなWebアプリ化したい  
(springbootというのを使えばできるようになるらしい？)
#### 問題の解決方法
とにかくAIに質問し、無限に壁打ちをした  
それからqiitaの記事検索とたまにredditで英語で検索 
githubでサンプルコードを検索  
つかったAIはchatgpt・claudecode・gemini・copilot  
それぞれのAIで解説やサンプルコードの生成に違いがあったので全部に聞いて  
今回はこいつの解説がわかりやすいなと思ったらそこで壁打ちをした  
コメント収集のコードに関してはPythonで書かれたサンプルコードがたくさん落ちていて  
ライブラリも作られていたのでそれでわからないところがあったらAIに聞いた
#### 感想
大体1日10時間ほど作業し  
最後の1週間は画面の見過ぎの眼精疲労で左目の瞼がピクピク痙攣していたため  
温めるアイマスクなので目を回復をはからないといけなかった  
世の中に落ちてるサンプルコードを読んで理解するために  
AIに質問したりググったりで徐々にコードを理解し  
自分で書き上げていくのはとても楽しかった  
また時間が経っても自分が理解できるようにわからなかったことは全てコード内コメントに残しているので  
訓練校の同じクラスの人や、別のクラスの人でも読めば理解はできるはず...  
(なおコード1行に対して日本語が30行ほどあったり、とっ散らかっているので可読性はかなり低い)  
サンプルコードがPythonだらけでPythonならライブラリも作られていて  
簡単に実装できる状態だったので、こういった処理においては  
やはりPythonが得意分野なのだろうと検索しながら感じた  
またそれぞれのプログラミング言語で得意分野、土俵があるというのも痛感した  
後は、AIによる高速検索が学習効率を大幅に上げていたのでそれに助けられた  
AIがなければ半年とかはかかっていたと思う  
また何か作るのに熱中できるようなお題で作りたい
　  
